{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "501ca2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from scipy.stats import pearsonr, zscore\n",
    "from mne_bids import BIDSPath\n",
    "from functools import partial\n",
    "from nilearn.plotting import plot_markers\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchaudio\n",
    "from transformers import WhisperProcessor, WhisperModel, AutoFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fadb221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = WhisperModel.from_pretrained(\"openai/whisper-base\")\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"openai/whisper-base\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8581d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "\n",
    "bids_root = \"/srv/nfs-data/sisko/storage/ECoG_podcast/ds005574-1.0.2\" \n",
    "subject = '03'\n",
    "func = partial(zscore, axis=1)\n",
    "ecog_sr = 512\n",
    "whisper_sr = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff3681c",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f55ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_raw_audio(x, fs, to_fs=ecog_sr, lowcut=200, highcut=5000):\n",
    "\n",
    "    # See https://scipy-cookbook.readthedocs.io/items/ButterworthBandpass.html\n",
    "    def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = signal.butter(order, [low, high], btype=\"band\")\n",
    "        return b, a\n",
    "\n",
    "    def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = signal.lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "    assert x.ndim == 1\n",
    "\n",
    "    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=5)\n",
    "    envelope = np.abs(signal.hilbert(y - y.mean()))\n",
    "\n",
    "    return envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b28e117d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1640395/3817159216.py:3: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  audio_sf, audio_wave = wavfile.read(audio_path)\n"
     ]
    }
   ],
   "source": [
    "audio_path = f\"{bids_root}/stimuli/podcast.wav\"\n",
    "\n",
    "audio_sf, audio_wave = wavfile.read(audio_path)\n",
    "if audio_wave.ndim > 1:\n",
    "    audio_wave = audio_wave[:, 0]\n",
    "audio_wave_clean = preprocess_raw_audio(audio_wave, audio_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff5cf5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1640395/2145047478.py:1: FutureWarning: extension should start with a period \".\", but got: \"fif\". Prepending \".\" to form: \".fif\". This will raise an exception starting with MNE-BIDS 0.12.\n",
      "  file_path = BIDSPath(root=bids_root+\"/derivatives/ecogprep\",\n"
     ]
    }
   ],
   "source": [
    "file_path = BIDSPath(root=bids_root+\"/derivatives/ecogprep\",\n",
    "                     subject=subject,\n",
    "                     task=\"podcast\",\n",
    "                     datatype=\"ieeg\",\n",
    "                     description=\"highgamma\",\n",
    "                     suffix=\"ieeg\",\n",
    "                     extension=\"fif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f862a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_whisper_embedding(audio, T):\n",
    "\n",
    "#     model.encoder.embed_positions = nn.Embedding(T, 512)\n",
    "#     model.eval()\n",
    "#     audio = torchaudio.transforms.Resample(audio_sf, whisper_sr)(torch.tensor(audio).float())\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c6e8129",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_path = f\"{bids_root}/stimuli/podcast_transcript.csv\"\n",
    "\n",
    "df = pd.read_csv(transcript_path)\n",
    "df.dropna(subset=['start'], inplace=True)\n",
    "df.sort_values(\"start\", inplace=True)\n",
    "events = np.zeros((len(df), 3))\n",
    "events[:, 0] = df.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27678f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stimuli_and_brain(file_path, audio_wave_clean, audio_sf, df, events, tmax=2.0):\n",
    "\n",
    "    raw = mne.io.read_raw_fif(file_path, verbose=False)\n",
    "    raw.load_data(verbose=False)\n",
    "    # raw = raw.apply_function(func, channel_wise=False, verbose=False)\n",
    "\n",
    "    epochs = mne.Epochs(\n",
    "        raw,\n",
    "        (events * raw.info['sfreq']).astype(int),\n",
    "        tmin=-1.0,\n",
    "        tmax=tmax,\n",
    "        baseline=None,\n",
    "        proj=None,\n",
    "        event_id=None,\n",
    "        preload=True,\n",
    "        event_repeated=\"merge\",\n",
    "        verbose=False\n",
    "    )\n",
    "    epochs_snippet = epochs._data\n",
    "    good_idx = epochs.selection\n",
    "    print(f\"Epochs object has a shape of: {epochs_snippet.shape}\")\n",
    "\n",
    "    audio_snippet = np.zeros((len(good_idx), int(tmax * audio_sf)))\n",
    "    for idx, row in tqdm.tqdm(enumerate(good_idx)):\n",
    "        row = df.iloc[idx]\n",
    "        start_sample = int((row['start']) * audio_sf) \n",
    "        end_sample = start_sample + int(tmax * audio_sf)\n",
    "        snippet = audio_wave_clean[start_sample:end_sample]\n",
    "        if len(snippet) < int(tmax * audio_sf):\n",
    "            padding_len = int(tmax * audio_sf) - len(snippet)\n",
    "            snippet = np.pad(snippet, (0, padding_len), mode='constant')\n",
    "        audio_snippet[idx, :] = snippet\n",
    "    print(f\"Audio object has a shape of: {audio_snippet.shape}\")\n",
    "\n",
    "    return epochs_snippet, audio_snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46e6d3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs object has a shape of: (5130, 235, 1537)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5130it [00:01, 3075.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio object has a shape of: (5130, 88200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "brain_data, audio_data = get_stimuli_and_brain(file_path, audio_wave_clean, audio_sf, df, events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bcf10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1ee023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4d42f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-meg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
